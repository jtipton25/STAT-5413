[
["day-26.html", "26 Day 26 26.1 Announcements 26.2 Multivariate Data 26.3 Classical Multivariate Geostatistics", " 26 Day 26 library(tidyverse) library(fields) library(mvnfast) library(LaplacesDemon) library(patchwork) library(GGally) 26.1 Announcements 26.2 Multivariate Data At each location \\(\\mathbf{s} \\in \\mathcal{D}\\) there are \\(p\\) variables \\(y_1(\\mathbf{s}), \\ldots, y_p(\\mathbf{s})\\) measured Examples: temperature and ozone precipitation and humidity Advantages of a joint model – why not just model each variable independently? Learn about any potential dependence between the variables Use cross-correlation to “borrow strength” among the variables to improve prediction and estimation Sometimes the processes are only partially observed (i.e., if there are two varaibles of interest, you might only observe one variable at a handful of sites, the other variable at other sites, and both variables at a subset to sites) draw picture can even fit a model if none of the variables are co-located if you make assumptions about the spatial co-dependence 26.3 Classical Multivariate Geostatistics 26.3.1 cross-variograms and cross-covariance functions The cross-variograms between variables \\(i\\) and \\(j\\) at lag \\(\\mathbf{h}\\) is \\[\\begin{align*} \\gamma_{ij}(\\mathbf{h}) = \\frac{1}{2} E\\left( \\left( y_i(\\mathbf{s} + \\mathbf{h}) - y_i(\\mathbf{s}) \\right) \\left( y_j(\\mathbf{s} + \\mathbf{h}) - y_j(\\mathbf{s}) \\right) \\right) \\end{align*}\\] where we assume that \\(E\\left( y_i(\\mathbf{s} + \\mathbf{h}) - y_i(\\mathbf{s}) \\right) = 0\\) for all \\(\\mathbf{s}\\) and \\(\\mathbf{s} + \\mathbf{h} \\in \\mathcal{D}\\) The cross-covariance function is \\[\\begin{align*} C_{ij}(\\mathbf{h}) = E\\left( \\left( y_i(\\mathbf{s} + \\mathbf{h}) - \\mu_i \\right) \\left( y_j(\\mathbf{s} + \\mathbf{h}) - \\mu_j \\right) \\right) \\end{align*}\\] where a constant mean \\(\\mu_i\\) is assumed. Note: cross-covariace function satisfies \\(| C_{ij}(\\mathbf{h}) |^2 \\leq C_{ii}(\\mathbf{0})C_{jj}(\\mathbf{0})\\) but \\(| C_{ij}(\\mathbf{h}) |\\) need not be \\(\\leq C_{ij}(\\mathbf{0})\\) 26.3.2 Cokriging use the multivariate vector for prediction by “borrowing strength” assume valid mean and cross-covariance functions, then cokriging can be done using multivariate normal distributions Let \\(\\mathbf{y} = \\left(y_1(\\mathbf{s_1}), \\ldots, y_1(\\mathbf{s_n}), y_2(\\mathbf{s_1}), \\ldots, y_2(\\mathbf{s_n}), \\ldots, y_p(\\mathbf{s_1}), \\ldots, y_p(\\mathbf{s_n}) \\right)&#39;\\) \\[\\begin{align*} \\mathbf{y} &amp; \\sim N(\\mathbf{X} \\boldsymbol{\\beta}, \\boldsymbol{\\Sigma}) \\end{align*}\\] in general, it is hard to choose a valid cross-covariance function so the matrix \\(\\boldsymbol{\\Sigma}\\) is hard to specify Instead, one can use a “seperable” covariance function \\[\\begin{align*} C_{ij}(\\mathbf{h}) &amp; = \\sigma_{ij} C(\\mathbf{h}) \\end{align*}\\] where \\(\\sigma_{ij}\\) is a cross-correlation between variable \\(i\\) and \\(j\\) that is independent of spatial location and \\(C(\\mathbf{h})\\) is a purely spatial covariance function This implies: Variance \\(Var(y_i(\\mathbf{s})) = \\sigma_{ii}\\) Cross-covariance \\(Cov(y_i(\\mathbf{s}), y_j(\\mathbf{s})) = \\sigma_{ij}\\) Spatial covariance \\(Cov(y_i(\\mathbf{s}), y_i(\\mathbf{s}&#39;)) = \\sigma_{ii} C(\\mathbf{s} - \\mathbf{s}&#39;)\\) Cross spatial covariance \\(Cov(y_i(\\mathbf{s}), y_j(\\mathbf{s}&#39;)) = \\sigma_{ij} C(\\mathbf{s} - \\mathbf{s}&#39;)\\) Hence, seperability implies the cross-covariance between responses is the same from site to site (the interrelationships between the variables are constant across space) and the spatial correlation is the same for each of the variable types Then, \\(\\boldsymbol{\\Sigma} = \\boldsymbol{\\Sigma}_p \\otimes \\mathbf{R}_n\\) where \\(\\boldsymbol{\\Sigma}_p\\) is the \\(p \\times p\\) covariance matrix among the \\(p\\) variables and \\(\\mathbf{R}_n\\) is the \\(n \\times n\\) spatial correlation matrix. ## Make some data set.seed(1) n &lt;- 20^2 p &lt;- 4 coords &lt;- expand.grid( seq(0, 1, length.out = sqrt(n)), seq(0, 1, length.out = sqrt(n)) ) X &lt;- cbind(1, rnorm(n, 0, 0.5)) beta &lt;- list(p) for (j in 1:p) { beta[[j]] &lt;- as.matrix(c(1, rnorm(1, 0, 0.5))) } Xbeta &lt;- rep(0, n * p) for (j in 1:p) { Xbeta[1:n + (j-1)*n] &lt;- X %*% beta[[j]] } sigma2 &lt;- 1 phi &lt;- 3 / 0.5 D &lt;- as.matrix(rdist(coords)) R_n &lt;- exp(-phi * D) ## simulate a 4 by 4 covariance matrix for the nu &lt;- p+1 Sigma_p &lt;- nu * rinvwishart(nu, diag(p)) ggcorr(data = NULL, cor_matrix = cov2cor(Sigma_p), label = TRUE) + scale_fill_viridis_c() + ggtitle(&quot;Correlation among processes&quot;) Note: we need to evaluate the Cholesky of \\(\\boldsymbol{\\Sigma}_p \\otimes \\mathbf{R}_n\\) for both simulation and estimation of the process. However, this is enabled computationally by noticing that \\[\\begin{align*} \\boldsymbol{\\Sigma}_p \\otimes \\mathbf{R}_n &amp; \\mathbf{L}\\mathbf{L}&#39; \\\\ &amp; = \\mathbf{L}_n \\otimes \\mathbf{L}_p \\end{align*}\\] This is commonly called “tensor products” or “tensor multiplication” – Google’s Tensorflow all.equal( kronecker(chol(Sigma_p), chol(R_n)), chol(kronecker(Sigma_p, R_n)) ) ## [1] TRUE ## calcuate the timings of the different operations bm &lt;- microbenchmark( kronecker(chol(Sigma_p), chol(R_n)), chol(kronecker(Sigma_p, R_n)), times = 10 ) bm ## Unit: milliseconds ## expr min lq mean median ## kronecker(chol(Sigma_p), chol(R_n)) 24.19185 24.94436 41.82493 30.64266 ## chol(kronecker(Sigma_p, R_n)) 618.73432 623.19167 626.64992 626.42762 ## uq max neval ## 32.1485 156.1825 10 ## 630.2370 635.3287 10 plot(bm) ## Note: this is slow # w &lt;- c(mvnfast::rmvn(1, rep(0, n*p), kronecker(Sigma_p, R_n))) ## instead use the decomposed Cholesky represntation w &lt;- c(mvnfast::rmvn(1, rep(0, n*p), kronecker(chol(Sigma_p), chol(R_n)), isChol = TRUE)) y &lt;- rnorm(n * p, Xbeta + w, sqrt(sigma2)) dat &lt;- data.frame( lon = coords[, 1], lat = coords[, 2], mu = Xbeta, w = w, y = y, var = rep(1:p, each = n) ) p1 &lt;- ggplot(data = dat, aes(x = lon, y = lat, fill = w)) + geom_raster() + facet_grid(~ var) + ggtitle(&quot;spatial random effects&quot;) p2 &lt;- ggplot(data = dat, aes(x = lon, y = lat, fill = mu)) + geom_raster() + facet_grid(~ var) + ggtitle(&quot;fixed effects&quot;) p3 &lt;- ggplot(data = dat, aes(x = lon, y = lat, fill = y)) + geom_raster() + facet_grid(~ var) + ggtitle(&quot;observed data&quot;) ## plot using patchwork package p1 / p2 / p3 26.3.3 Linear Model of Coregionalization essentially a spatial version of factor analysis the responses are a \\(p\\)-vector \\((y_1(\\mathbf{s}), \\ldots, y_p(\\mathbf{s}))&#39;\\) at each location (maybe only partially observed) Idea: instead of there being \\(p\\) different processes, these can be represented by \\(L &lt; p\\) latent (unobserved) sources \\(f_1(\\mathbf{s}), \\ldots, f_L(\\mathbf{s})\\) very common in pollution / air quality monitoring each of the \\(f_\\ell(\\mathbf{s})\\) can be thought of as different sources of pollutions (e.g., cars, power plants, manufacturing plants, etc.) The factor analysis model (linear model of coregionalization) is \\[\\begin{align*} y_i(\\mathbf{s}) &amp; = \\sum_{\\ell = 1}^L A_{i \\ell} f_{\\ell}(\\mathbf{s}) + \\varepsilon{s} \\end{align*}\\] where \\(\\varepsilon(\\mathbf{s}) \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) The joint model is \\[\\begin{align*} \\mathbf{y}(\\mathbf{s}) = \\begin{pmatrix} y_1(\\mathbf{s}) \\\\ \\vdots \\\\ y_p(\\mathbf{s}) \\sim N(\\mathbf{A} \\mathbf{f}(\\mathbf{s}), \\mathbf{D}) \\end{pmatrix}, \\end{align*}\\] where \\(\\mathbf{A} = \\begin{pmatrix} \\mathcal{R}^+ &amp; 0 &amp; \\cdots &amp; 0\\\\ \\mathcal{R} &amp; \\mathcal{R}^+ &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\mathcal{R} &amp; \\cdots &amp; \\mathcal{R} &amp; \\mathcal{R}^+ \\end{pmatrix}\\) is a \\(p \\times L\\) lower triangular matrix with positive diagonal elements (\\(\\mathcal{R}^+\\)) and unconstrained values in the lower triangle (\\(\\mathcal{R}\\)). These requirements are to ensure the model is identifiable. The \\(\\mathbf{f}(\\mathbf{s}) = (f_1(\\mathbf{s}), \\ldots, f_p(\\mathbf{s}))&#39;\\) is a \\(p\\)-vector of spatially correlated latent factors, and \\(\\mathbf{D} = \\begin{pmatrix} \\sigma^2_{11} &amp; 0 &amp; \\cdots &amp; 0\\\\ 0 &amp; \\sigma^2_{22} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; \\sigma^2_{pp} \\end{pmatrix}\\) is a diagonal matrix with positive diagonals representing the nugget variances for each of the \\(p\\) variables Seperable model: If the latent processes \\(f_i\\) are \\(iid\\) GPs with mean zero, variance 1 and correlation \\(C(\\|\\mathbf{s} - \\mathbf{s}&#39;\\| | \\boldsymbol{\\theta})\\), then the covariance is \\[\\begin{align*} Cov \\left( y(\\mathbf{s}), y(\\mathbf{s}&#39;) \\right) &amp; = Cov \\left( \\mathbf{A} \\mathbf{f}(\\mathbf{s}), \\mathbf{A} \\mathbf{f}(\\mathbf{s}&#39;) \\right) \\\\ &amp; = \\mathbf{A} Cov \\left( \\mathbf{f}(\\mathbf{s}), \\mathbf{f}(\\mathbf{s})\\right) \\mathbf{A}&#39;\\\\ &amp; = \\mathbf{A} \\begin{pmatrix} Cov(f_1(\\mathbf{s}), f_1(\\mathbf{s})) &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; Cov(f_2(\\mathbf{s}), f_2(\\mathbf{s})) &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; Cov(f_L(\\mathbf{s}), f_L(\\mathbf{s})) \\end{pmatrix} \\mathbf{A}&#39; \\\\ &amp; \\mathbf{A} \\mathbf{A}&#39; C(\\|\\mathbf{s} - \\mathbf{s}&#39;\\|), \\end{align*}\\] where \\(\\mathbf{A} \\mathbf{A}&#39;\\) is the cross-covariance and \\(C(\\|\\mathbf{s} - \\mathbf{s}&#39;\\|)\\) is the spatial covariance Non-seperable model: If the latent processes \\(f_i\\) are \\(iid\\) GPs with mean zero, variance 1 but the latent process \\(j\\) has correlation function \\(C(\\|\\mathbf{s} - \\mathbf{s}&#39;\\| | \\boldsymbol{\\theta}_j)\\), then the covariance is \\[\\begin{align*} Cov \\left( y(\\mathbf{s}), y(\\mathbf{s}&#39;) \\right) &amp; = Cov \\left( \\mathbf{A} \\mathbf{f}(\\mathbf{s}), \\mathbf{A} \\mathbf{f}(\\mathbf{s}&#39;) \\right) \\\\ &amp; = \\mathbf{A} Cov \\left( \\mathbf{f}(\\mathbf{s}), \\mathbf{f}(\\mathbf{s})\\right) \\mathbf{A}&#39;\\\\ &amp; = \\mathbf{A} \\begin{pmatrix} Cov(f_1(\\mathbf{s}), f_1(\\mathbf{s})) &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; Cov(f_2(\\mathbf{s}), f_2(\\mathbf{s})) &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; Cov(f_L(\\mathbf{s}), f_L(\\mathbf{s})) \\end{pmatrix} \\mathbf{A}&#39; \\end{align*}\\] is non-seperable \\[\\begin{align*} a \\end{align*}\\] "]
]
